\appendix
\section*{Appendix}
%
\section{Detailed Experimental Results}\label{appendix:extended_result}
\rmcmt{recount total benchmarks in tables}
Table~\ref{detailed_result} gives a detailed comparison between CBMC version
5.5 and ACDLP.  Columns~1--4 in Table~\ref{detailed_result} contain the
name of the tool, the benchmark category, the number of lines of code (LOC),
and the total number of safe and unsafe benchmarks in the respective
categories (labelled as safe/unsafe).  The solver statistics ({\em
Decisions, Propagations, Conflicts, Conflict Literals, Restarts}) per
category for CBMC and ACDLP are in columns~5--9.
%
%Column~10 reports the total time for verification per category.  

We divide the benchmarks into separate categories. 
We label the benchmarks in bit-vector regression category in SV-COMP'16 
as {\em Bit-vector}, C models of hardware circuits auto-generated by v2c 
tool as {\em Verilog-C} and hand-crafted benchmarks as {\em Control-Flow} 
category.  The total number of benchmarks in {\em bit-vector} category are 13, 
{\em Control-Flow} category contains 55 benchmarks and 
{\em Verilog-C} category has 10 benchmarks. The timeout for our
experiments is set to one hour.  All times in Table~\ref{detailed_result} 
and Table~\ref{ai-result} are in seconds. 

The benchmarks in Bit-vector category are derived from bit-vector regression
category in SV-COMP'16.  This categoty contains a total of six safe
benchmarks and~seven unsafe benchmarks.  The benchmarks in the control-flow
category vary from simple bounded loop analysis and implementation of
arithmetic operations to more complex checking for relational properties in
nested loops.  Out of~55 benchmarks in this category, 38 are safe and 17 are
unsafe.  We verified a total of ten hardware benchmarks, which are given in
Verilog.  Out of those ten benchmarks, five are safe and the remaining five
are unsafe.  The software models (in C) for the Verilog circuits are
obtained via a Verilog to C translator tool, {\em v2c}.  These software
models are then fed to CBMC and ACDLP.  The hardware benchmarks include an
implementation of a Instruction buffer logic, FIFO arbiter, traffic light
controller, cache coherence protocol, Dekker's mutual exclusion algorithm
among others.  The largest benchmark is the cache coherence protocol which
consists of~890 LOC and the smallest benchmark is TicTacToe with~67 LOC. 
The software models of these Verilog circuits uses several complex bit-wise
logic to map hardware operations into an equivalent C syntax.  It is worth
emphasizing that our abstract domain implementation can automatically handle
bit-wise operations out-of-the-box.
%
\begin{table}[!b]
\begin{center}
{
\begin{tabular}{l|l|r|r|r|r|r|r|r}
\hline
           &          &     & Safe/  &           & Propa-  &           & Conflict &          \\
  Verifier & Category & LOC & Unsafe & Decisions & gations & Conflicts & literals & Restarts \\ \hline
  CBMC & \multirow{2}{*}{Bit-vector} & \multirow{2}{*}{501} &
  \multirow{2}{*}{6/7} & 1011 & 1190 & 0 & 0 & 7 \\
  ACDLP & & & & 0 & 44 & 0 & 0 & 0 \\ \hline
  CBMC & \multirow{2}{*}{Control-Flow} & \multirow{2}{*}{692} & 
  \multirow{2}{*}{38/17} & 29382 & 379727 & 4520 & 37160 & 62 \\ 
  ACDLP & & & & 414 & 6487 & 195 & 180 & 0  \\ \hline
  CBMC & \multirow{2}{*}{Verilog-C} & \multirow{2}{*}{2422} & 
  \multirow{2}{*}{5/5} & 131932 & 322707 & 69 & 349 & 6 \\ 
  ACDLP & & & & 625 & 8196 & 22 & 22 & 0 \\ \hline
  %CBMC & \multirow{2}{*}{Numerical} & \multirow{2}{*}{} & 
  %\multirow{2}{*}{} & & & & & & \\
  %ACDLP & & & & 161 & 3130 & 10 & 5 & 0 & \\ \hline  
\end{tabular}
}
\end{center}
\caption{CBMC versus ACDLP}
\label{detailed_result}
\end{table}
%
The statistics reported in Table~\ref{detailed_result} for ACDLP is obtained 
with an ordered decision heuristic, multi-way propagation heuristic and a
first-UIP learning heuristic.  Note that the deductions using a 
multi-way heuristic are more precise than the forward or backward 
heuristics, but it takes longer time to reach the fixed-point.
Another advantage of multi-way heuristic is that it significantly 
reduces the overall number of decisions and learning iterations due to stronger 
and more precise deductions.  Analysis using ACDLP reduces the total number of 
decisions, propagations and learning compared to CBMC by a factor of~2X.  
%
\begin{table}[t]
\begin{center}
{
\begin{tabular}{l|l|r|r|r}
\hline
  Verifier & Category & \#Proved (safe/unsafe) & \#Inconclusive & \#False Positives \\ \hline
  Astr{\'e}e & \multirow{2}{*}{Bit-vector} & 5/7 & 0 & 1 \\
  ACDLP & & 6/7 & 0 & 0 \\ \hline
  Aste{\'e}e & \multirow{2}{*}{Control-Flow} & 24/9 & 0 & 22 \\
  ACDLP & & 35/17 & 3 & 0 \\ \hline
  Astr{\'e}e & \multirow{2}{*}{Verilog-C} & 2/4 & 0 & 4 \\
  ACDLP & & 4/5 & 1 & 0 \\ \hline
  %Astr{\'e}e & \multirow{2}{*}{Numerical(13)} & 6/7 &  & \\
  %ACDLP & & & & \\ \hline
\end{tabular}
}
\end{center}
  \caption{Astr{\'e}e versus ACDLP}
\label{ai-result}
\end{table}
%
Table~\ref{ai-result} gives a detailed comparison between Astr{\'e}e and
ACDLP.  Columns~1--5 in Table~\ref{ai-result} contain the name of the
tool, the benchmark category, the total number of instances proved safe or
unsafe (labelled as safe/unsafe), the total number of inconclusive
benchmarks and total number of false positives per category.

To enable precise analysis using Astr{\'e}e, we manually instrumented 
partition directives in some benchmarks.  These directives provides 
external hint to the tool to guide the trace partitioning heuristics.  
Note that it requires significant domain knowledge to select the right 
partition directive.  Usually, such high-precision is not needed for 
static analysis, since it makes the analysis very expensive.  Without 
trace partitioning, the analysis using Astr{\'e}e shows high degree of 
imprecision. 

Table~\ref{ai-result} shows that ACDLP proved more benchmarks than
Astr{\'e}e in all categories.  The total number of inconclusive results in
ACDLP is three.  The inconclusive results is because of timeout.  By
contrast, Astr{\'e}e reports a total of~27 false positives among~78
benchmarks even with manual trace partitioning.  Clearly, ACDLP is more
precise than the analysis in Astr{\'e}e.
%
%
\section{Decision Heuristics in ACDLP}
%
We have implemented several decision heuristics in ACDLP: {\em ordered}, 
{\em longest-range}, {\em random}, and the {\em Berkmin}~\cite{eugoldberg07} 
decision heuristic.  The {\em ordered} decision heuristic 
%creates an ordering among meet irreducibles, 
makes decisions on meet irreducibles that involve conditional 
variables (variables that appear in conditional branches) first 
before choosing meet irreducibles with numerical variables.  
%The ordered heuristic gives an effect of trace partitioning~\cite{toplas07}.
%
The {\em longest-range} heuristic simply keeps track of the bounds
$\numabsval_l,\numabsval_u$ of matching template rows, which are 
%\footnote{These are template rows with row vectors $\vec{c}$, $\vec{c}'$ such that $\vec{c}=-\vec{c}'$.}
row vectors $\vec{c}$, $\vec{c}'$ such that $\vec{c}=-\vec{c}'$.
%\pscmt{[that has become a bit hard to understand since some of the definitions have been removed]} 
$\numabsval_l\leq \vec{c}\vec{x}\leq \numabsval_u$, picks the one with the longest range
$\numabsval_u-\numabsval_l$, and randomly returns the meet irreducible
$\vec{c}\vec{x}\leq
\lfloor\frac{\numabsval_l+\numabsval_u}{2}\rfloor$ or its
complement. This ensures a fairness policy in selecting a variable
since it guarantees that the intervals of meet irreducibles are
uniformly restricted.
%
The {\em random} decision heuristic arbitrarily picks a meet irreducible  
for making decision. 
%
%The {\em relational} decision heuristics is only relevant for relational 
%abstract domains.  
%
The {\em Berkmin} decision heuristic is inspired by the 
decision heuristic used in the Berkmin~\cite{eugoldberg07} SAT solver.  
The Berkmin heuristic %is currently implemented for interval constraints only.  
%The heuristic 
keeps track of the activity of %an interval 
meet irreducibles that participate in conflict clauses. 
Based on the most active meet irreducible, ranges are split 
similar to the {\em longest-range} heuristic.
%
\section{Comparison of Solving Statistics in ACDLP}
%
\input{graph2}
%
\paragraph{Propagation Strategy.}
%
Fig.~\ref{prop-dec}(a) presents a comparison between the {\em forward}
propagation strategy and the {\em multi-way} propagation strategy in ACDLP.  The
choice of strategy influences the total number of decisions
and clause learning iterations.  Hence, the propagation strategy has a
significant influence on the runtime, which can be seen in
Fig.~\ref{prop-dec}(a).  Compared to forward propagation, the multi-way
strategy may take more iterations to reach the fixed-point, but it
significantly reduces the number of decisions and conflicts, in
particular for the unsafe benchmarks.  This is attributed to the higher
precision of the meet irreducibles inferred by the multi-way strategy, which
subsequently aids the decision heuristics to make better decisions.

\paragraph{Decision Heuristics.}
%
Fig.~\ref{prop-dec}(b) shows the performance of different decision
heuristics in ACDLP.  Note that the runtimes for all decision heuristics are
obtained with the multi-way propagation strategy.  The runtimes are very
close, but we can still discern some key characteristics of these
heuristics.  The Berkmin heuristic performs consistently well for most safe
benchmarks and all bit-vector category benchmarks.  By contrast, the ordered
heuristic performs better for programs with conditional branches since it
prioritises decisions on meet irreducibles that appear in conditionals.  The
runtimes for the random heuristic are marginally higher than for the other
two.  This suggests that domain-specific decision heuristics are important
for ACDLP.
%
%\tmcmt{I don't see any such conclusion can be reached from the
%graph shown. It looks, at least at this scale, like it really doesnt matter which
%heuristic is used! And if RANDOM is best, well this contradicts the last sentence, doesn't it?}

\Omit{
Whereas activity-based heuristics such as Berkmin heuristic which 
works well in propositional cases performs best for benchmarks 
that encountered the maximum number of conflicts to prove safety, 
thus allowing the heuristics to choose the decision variable among the set of learnt clauses.   
}

\paragraph{Learning.}
%
Learning has a significant influence on the runtime of ACDLP.  We compare
the UIP-based learning technique with an analysis that performs classical 
DPLL-style analysis~\cite{DPLL62}.
%chronoligical backtracking without learning.  
The effect of UIP computation allows ACDLP to backtrack non-chronologically 
and guide the model search with a learnt transformer.  But classical 
DPLL-style analysis exhibits case-enumeration behaviour and could not finish 
within the time bound for 20\% of our benchmarks.
%
\section{Computing Lazy Closure in Template Polyhedra Domain}\label{appendix:lazyclosure}
%
Computing the closure for relational domains, such as octagons, is
expensive~\cite{pldi15}.  An~advantage of our formalism in
Eq.~(\ref{eq:at2}) is that the \emph{closure} operation for relational
domains can be computed in a lazy manner through the construction of a
subdomain.  A subdomain $\subdomain$ is constructed from domain $\domain$
for a abstract deduction transformer $\abstransel{\subdomain}$, such that
$\subdomain=\makesubdomain_\domain(\subvars)$, where $\subvars$ are
variables that appears in $\abstransel{\subdomain}$.  The construction of
$\subdomain$ allows us to perform one step of the closure operation when
$\abstransel{\subdomain}$ is applied.
%
For example, let us consider $\domain=\octagons[\{x,y,z\}]$ and
$\subvars=\{y\}$. An octagonal inequality relates at 
most two variables. Thus it is sufficient to consider the subdomain
$\makesubdomain_\domain(\{y\})=\octagons[\{y\}]\cup\octagons[\{x,y\}]\cup\octagons[\{y,z\}]$,
which will compute the one-step transitive relations of~$y$ with each
of the other variables. 
%
Only if a abstract deduction transformer subsequently makes new deductions 
on $x$ or $z$, then the next step of the closure will be computed through 
the subdomain $\octagons[\{x,z\}]$.
\Omit{
Hence, when the abstract deduction transformer is applied we do not
compute the full closure in the full domain,
but we compute only a single step of the closure in a restricted
domain, which makes single deduction steps more efficient.
}
Hence, an application of abstract deduction transformer does not 
compute the full closure in the full domain, but compute only a 
single step of the closure in a restricted domain, which makes each 
deduction step more efficient.  Thus, we delay the closure operation 
until the point where it is absolutely necessary.  
%This makes our deductions in relational domain more efficient.  
%

Let us demonstrate the idea of lazy closure with a concrete example.  Assume
the program in the left of Figure~\ref{fig:lazy}.  The corresponding
locations are marked as L1, L2.  We~analyze the program with an octagon
domain ($\octagons$), which computes the closure in lazy manner.  The lazy
closure computation in octagon domain is shown in the right of
Figure~\ref{fig:lazy}.

Recall that a closure in octagon domain achieves a normal form by computing all
implied constraints among numerical variables. The closure operation is 
necessary to perform precise domain operations.  The ACDLP analysis in
Figure~\ref{fig:lazy} performs forward propagation in $\octagons$ by creating a 
subdomain $\subdomain$ for every transformer using the function $\makesubdomain$.  
Note that the choice of subdomain over lhs variables of the transformers guides the 
analysis in forward direction in this example. The subdomain 
corresponding to L1 over $y$ is given by 
$\octagons[\{y\}]\cup\octagons[\{y,z\}]$.  This means, only those deductions 
which are implied by the domain $\octagons[\{y\}]\cup\octagons[\{y,z\}]$ can be
inferred at L1.  No deductions over $\octagons[\{y,x\}]$ is performed at L1.  
Thus, we delay the deductions over $\{y,x\}$ until we encounter an abstract 
transformer over these variables.  This does not admit a normal form for 
octagonal constraints after the application of the transformer at L1, but it 
makes the deduction step at L1 more efficient.  

Assume that the initial abstract value $(\absval)$ is $\absval=(x=y)$. 
Then, the deduction at L1 infers ${y=z}$.  Thus, the updated abstract value
is $\absval=\{x=y \wedge y=z\}$.  We now analyze the transformer at L2.  The
subdomain for L2 over variable $x$ (for forward propagation) is given by
$\octagons[\{x\}]\cup\octagons[\{x,y\}]\cup\octagons[\{x,z\}]\cup\octagons[\{x,w\}]$. 
Note that we delayed the deduction over $\octagons[\{x,y\}]$ at L1, but only
perform the deductions over $\octagons[\{x,y\}]$ at L2.  This is the notion
of lazy closure computation.  The new deductions at L2 are $\{x=z, x-w \leq
1, x-w \geq 1\}$ and the final abstract value is $\absval=\{x=y
\wedge\allowbreak y=z \wedge\allowbreak x=z \wedge\allowbreak x-w \leq 1
\wedge x-w \geq 1\}$.  Thus, the normal form over $\octagons{\{x,y,z\}}$ is
only achieved at L2.  However, we do not perform deductions over
$\octagons{\{w,z\}}$ at L2, which is delayed until the point where we
encounter an abstract transformer that forces us to infer such deductions.
%
\begin{figure}[htbp]
\centering
\begin{tabular}{c|c}
\hline
C program & Lazy Closure Computation \\
\hline
\scriptsize
\begin{lstlisting}[mathescape=true,language=C]
int main() {
  L1: y=z;
  L2: x=w+1;
}
\end{lstlisting}
&
\begin{lstlisting}[mathescape=true,language=C]
L1: $\makesubdomain_\domain(\{y\})=\octagons[\{y\}]\cup\octagons[\{y,z\}]$
    New Deductions: $\{y=z\}$
    Abstract Value: $\absval=\{x=y \wedge y=z\}$
L2: $\makesubdomain_\domain(\{x\})=\octagons[\{x\}]\cup\octagons[\{x,y\}]\cup\octagons[\{x,z\}]\cup\octagons[\{x,w\}]$
    New Deductions: $\{x=z, x-w \leq 1, x-w \geq 1\}$
    Abstract Value: $\absval=\{x=y \wedge y=z \wedge x=z \wedge x-w \leq 1 \wedge x-w \geq 1\}$
\end{lstlisting}
\\
\hline
\end{tabular}
\caption{\label{fig:lazy}
C Program and Lazy closure operation for Octagons}
\end{figure}
%
\section{Difference between ACDLP and CEGAR}
%
ACDLP is not, however, similar to abstraction refinement. ACDLP works on a fixed abstraction.  
Also, transformer learning in ACDLP does not soundly over-approximate the existing program 
transformers, hence it is distinct from transformer refinement in classical Counterexample 
Guided Abstraction Refinement (CEGAR).
%
%===============================================================================
\input{gamma-complete}
%===============================================================================
%
\section{Program and Property Driven Trace partitioning in ACDLP}
ACDLP performs automatic program and property driven trace partitioning. 
This is illustrated with an example in Figure~\ref{fig:tp}. Consider a 
simple program $P$ in left side of Figure~\ref{fig:tp}.  A simple forward 
interval analysis cannot prove safety of $P$ due to control-flow join 
following the if-else branch.  However, the analysis using ACDLP makes a decision 
on the variable $\langle y: [-\inf, 3] \rangle$ which implicitly constructs
a trace partitioning, as shown in right-hand side of Figure~\ref{fig:tp}. 
Interval analysis using above decision immediately leads to safety.  At 
this point, the analysis backtracks, discarding all propagations that leads to conflict, 
and learns that $\langle y: [4, +\inf] \rangle$.  Interval analysis also proves that 
$P$ is safe with the learnt clause.  The analysis cannot backtrack further and 
therefore terminates, proving that the program is safe.  
% 
\begin{figure}[htbp]
\centering
\begin{tabular}{c|c}
\hline
C program & Partitioned Program \\
\hline
\scriptsize
\begin{lstlisting}[mathescape=true,language=C]
void foo(int x, int y) 
{
  if(y < 4)
   x = 1;
  else 
   x = -1;
  assert(x != 0); 
}
\end{lstlisting}
&
\begin{lstlisting}[mathescape=true,language=C]
void foo_partitioned() 
{
  if(y < 4) {
   foo(x, y);
   assert(x != 0); 
  }
  else {
    foo(x, y);
    assert(x != 0); 
  }
}
\end{lstlisting}
\\
\hline
\end{tabular}
\caption{\label{fig:tp}
C Program and its corresponding partitions}
\end{figure}
%
The above example illustrates that ACDLP automatically performs 
program and property-driven trace partitioning.  The partition is 
program dependant because if the branch condition in $P$ was $(y<10)$, 
then ACDLP would have generated a different partition, 
$\langle y: [-\infty, 9], y: [10, +\infty] \rangle$. The partition is 
property-dependant because if the assertion was $assert(x < 1)$, then 
no splitting would have been needed to prove safety. 
%
\Omit{
\section{Correspondance between Propositional CDCL and Abstract Interpretation}
%
The correspondences between propositional CDCL and lattice-based abstractions are 
shown in Table~\ref{connection}. 
\begin{table}[]
\centering
\caption{Components in propositional solver and their counterparts in
  lattice-theory}
\label{connection}
\begin{tabular}{ll}
\hline  
  Propositional Solver & Abstract Interpretation \\
\hline
Partial assignment & Abstract Domain with complementable meet irreducibles \\
Singleton assignments & Meet Irreducibles   \\
CNF formula & Abstract Deduction Transformer    \\
Unit rule & Best Abstract Transformer \\
BCP & Greatest Fixed-Point Computation \\
Decision & Dual Widening \\ 
Conflict Analysis & Abductive Reasoning \\
Clause Learning & Synthesizing Abstract Transformer for negation \\ 
\hline
\end{tabular}
\end{table}
%
\section{Abstract DPLL versus Abstract CDCL}
%
Fig.~\ref{fig:dpll} and Fig.~\ref{fig:cdcl} demonstrates the Abstract DPLL
style (ADPLL) analysis and Abstract CDCL-style (ACDLP) analysis with
interval domain.  Figure~\ref{fig:dpll} and Figure~\ref{fig:cdcl} give a
program on the left and the result of ADPLL and ACDLP analysis on the right,
respectively.  Starting with a decision $x=[0,\infty]$, both the analysis
could not infer deductions necessary for proving safety.  Hence, it makes a
decision $y=[0,\infty]$, which also does not lead to safety.  The analysis
now makes further decisions on variable $y$, which eventually lead to a {\em
proof}.  At this point, a ADPLL-style analysis performs a case-based
reasoning, that is, try $y=[-\infty, 4]$.  However, a ACDCL-style analysis
performs a generalization step which shows that the proof is valid even when
$y=[4,\infty]$.  The ACDCL analysis learns the reason for the conflict.  It
performs deductions with the learnt clause and immediately proof safety. 
The ADPLL analysis requires a total of 14 decisions to prove safety, whereas
ACDLP analysis requires only 4 decisions to prove safety.  This demonstrates
the benefit of learning in ACDLP-style analysis over ADPLL.

\begin{figure}[t]
\centering
\begin{tabular}{c|c}
\hline
C program & DPLL with Forward Interval Analysis \\
\hline
\scriptsize
\begin{lstlisting}[mathescape=true,language=C]
int main()
{
  if(y<4)
   x=1;
  else 
   x=-1;
  assert(x!=0);
}
\end{lstlisting}
&
\begin{lstlisting}[mathescape=true,language=C]
1. x:[0,$\infty$]
2. x:[0,$\infty$], y:[0,$\infty$]
3. x:[0,$\infty$], y:[5,$\infty$] $\implies$ PROOF
4. x:[0,$\infty$], y:[-$\infty$,4]
5. x:[0,$\infty$], y:[-$\infty$,3] $\implies$ PROOF
6. x:[0,$\infty$], y:[4,4] $\implies$ PROOF
7. x:[0,$\infty$], y:[-$\infty$,0]

8. x:[-$\infty$,0]
9. x:[-$\infty$,0], y:[0,$\infty$]
10. x:[-$\infty$,0], y:[5,$\infty$] $\implies$ PROOF
11. x:[-$\infty$,0], y:[-$\infty$,4]
12. x:[-$\infty$,0], y:[-$\infty$,3] $\implies$ PROOF
13. x:[-$\infty$,0], y:[4,4] $\implies$ PROOF
14. x:[-$\infty$,0], y:[-$\infty$,0] $\implies$ PROOF
\end{lstlisting}
\\
\hline
\end{tabular}
\caption{\label{fig:dpll}
DPLL-style Analysis with Intervals}
\end{figure}

\begin{figure}[t]
\centering
\begin{tabular}{c|c}
\hline
C program & CDCL with Forward Interval Analysis \\
\hline
\scriptsize
\begin{lstlisting}[mathescape=true,language=C]
int main()
{
  if(y<4)
   x=1;
  else 
   x=-1;
  assert(x!=0);
}
\end{lstlisting}
&
\begin{lstlisting}[mathescape=true,language=C]
1. x:[0,$\infty$]
2. x:[0,$\infty$], y:[0,$\infty$]
3. x:[0,$\infty$], y:[5,$\infty$] $\implies$ PROOF (Generalize y)
5. x:[0,$\infty$], y:[4,$\infty$] $\implies$ PROOF (Learn)
6. x:[0,$\infty$], y:[-$\infty$,3] $\implies$ PROOF
\end{lstlisting}
\\
\hline
\end{tabular}
\caption{\label{fig:cdcl}
CDCL-style Analysis with Intervals}
\end{figure}
}

%
\Omit{
\section{Octagon Analysis in ACDCL}
\rmcmt{correct the constraints}
\begin{figure}[t]
\centering
\begin{tabular}{c|c}
\hline
C program & Forward Octagon Analysis \\
\hline
\scriptsize
\begin{lstlisting}[mathescape=true,language=C]
int main()
{
  L0:int x,y,z,d,g;
  L1:assume(x==y || x==-y);
  L2:if(x<0)  d=-x;
  L3:else     d=x;  
  L4:if(y<0)  g=-y;
  L5:else     g=y;
  L6:z = d-g;    
  L7:assert(z==0);
}
\end{lstlisting}
&
\begin{lstlisting}[mathescape=true,language=C]
L1: [$\top$]
L2: [d-1>=0; d+x>=0; -d-x>=0; d-x-2>=0; -x-1>=0]
L3: [d>=0; -d+x>=0; d+x>=0; x>=0; d-x>=0]
L4: [d>=0; d+g-1>=0; g-1>=0; d+x>=0; d-x>=0; 
     g+y>=0; d-y-1>=0;-g-y>=0; g-y-2>=0; -y-1>=0]
L5: [d>=0; d+g>=0; g>=0; d+x>=0; d-x>=0; 
     g+y>=0; g-y>=0]
L6: [d>=0; d+g>=0; g>=0; d+x>=0; d-x>=0; 
     g+y>=0; g-y>=0; g+z>=0; d-z>=0]
L7: [$\top$]     
\end{lstlisting}
\\
\hline
\end{tabular}
\caption{\label{fig:octagon}
C Program and its corresponding forward octagon analysis}
\end{figure}
}
%
\Omit{
\section{Polyhedral Analysis with Multi-way Interval Analysis}
%
Consider the program in left of Fig.~\ref{fig:interval} 
and the corresponding standard forward interval analysis 
shown in the right.  Fig.~\ref{fig:polyhedra} shows the 
corresponding octagon and polyhedral analysis in the left and 
right side respectively. Clearly, only polyhedral analysis can 
prove safety of the program.  This is because the expression $y\leq2*x$ in the 
{\em assert} statement can only be expressed with a polyhedra 
abstract domain.  However, ACDLP with interval analysis
ACDLP can have the same precision of a standard forward polyhedral analysis 
in this case. \rmcmt{TBD}
%
\begin{figure}[t]
\centering
\begin{tabular}{c|c}
\hline
C program & Forward Interval Analysis \\
\hline
\scriptsize
\begin{lstlisting}[mathescape=true,language=C]
int main()
{
 L0:unsigned x,y,z;
 L1: assume(x>=1 && x<=5);
 L2: if(z>=0)
 L3:   y=2*x-1;
 L4:  else 
 L5:   y=2*x-2;
 L6: assert(y<=2*x);
}
\end{lstlisting}
&
\begin{lstlisting}[mathescape=true,language=C]
L1: [x-1>=0; -x+5>=0]
L2: [x-1>=0; -x+5>=0; z>=0]
L3: [x-1>=0; -x+5>=0; y-1>=0; -y+9>=0; z>=0]
L4: [x-1>=0; -x+5>=0; -z-1>=0]
L5: [x-1>=0; -x+5>=0; y-3>=0; -y+11>=0; -z-1>=0]
L6: [x-1>=0; -x+5>=0; y-1>=0; -y+11>=0] $\implies$ [$\top$]
\end{lstlisting}
\\
\hline
\end{tabular}
\caption{\label{fig:interval}
C Program and its corresponding forward interval analysis}
\end{figure}
%
\begin{figure}[t]
\centering
\begin{tabular}{c|c}
\hline
  Forward Octagon Analysis & Forward Polyedral Analysis \\
\hline
\scriptsize
\begin{lstlisting}[mathescape=true,language=C]
L1: [x-1>=0; -x+5>=0] 
L2: [x-1>=0; -x+5>=0; 
     -x+z+5>=0; x+z-1>=0; z>=0] 
L3: [x-1>=0; -x+5>=0; -x+y>=0; 
     x+y-2>=0; y-1>=0; -x-y+14>=0; 
     x-y+4>=0; -y+9>=0; -x+z+5>=0; x+z-1>=0;
     -y+z+9>=0; y+z-1>=0; z>=0] 
L4: [x-1>=0; -x+5>=0; -x-z+4>=0; 
     x-z-2>=0; -z-1>=0]
L5: [x-1>=0; -x+5>=0; -x+y-2>=0; x+y-4>=0; 
     y-3>=0; -x-y+16>=0; x-y+6>=0; -y+11>=0; 
     -x-z+4>=0; x-z-2>=0; -y-z+10>=0; 
     y-z-4>=0; -z-1>=0]
L6:  [x-1>=0; -x+5>=0; -x+y>=0; x+y-2>=0; 
      y-1>=0; -x-y+16>=0; x-y+6>=0; -y+11>=0] 
     $\implies$ [$\top$]
\end{lstlisting}
&
\begin{lstlisting}[mathescape=true,language=C]
L1: [-x+5>=0; x-1>=0]
L2: [-x+5>=0; z>=0; x-1>=0]
L3: [-2x+y+1=0; -x+5>=0; z>=0; x-1>=0]
L4: [-x+5>=0; -z-1>=0; x-1>=0]
L5: [-2x+y-1=0; -x+5>=0; -z-1>=0; x-1>=0]
L6: [-2x+y+1>=0; -x+5>=0; x-1>=0; 2x-y+1>=0]
    $\implies$ [$\bot$]
\end{lstlisting}
\\
\hline
\end{tabular}
\caption{\label{fig:polyhedra}
C Program and its corresponding forward polyhedral analysis}
\end{figure}
}
